{"cells":[{"cell_type":"markdown","source":["![logo](https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31)\n","\n","# **Fabric**\n","### Simulating streaming data for Realtime Analytics âš¡ using fabric Data Engineering notebook\n","### [Fabric RTA in a Day](https://aka.ms/fabricrtainaday) - Lab3 ðŸªµ\n","This notebook is used to take a CSV file with Log Data and stream it to Eventstreams as a simulated CustomApp source. \n","\n","The notebook will stream one row at at time (roughly 1 row/sec) into the CustomApp endpoint of the Eventstream. Eventstream will automatically ingest to the KQL database.\n","\n","##### Please set your `ConnectionString` value **in the first code cell**. \n","`insert screenshot create new eventstream`"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"38d676a7-70da-4860-b4e0-06fdfeadeaf3"},{"cell_type":"markdown","source":["##### 1st - sets variables"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"31331819-d046-43f6-924f-8c2f25147479"},{"cell_type":"code","source":["ConnectionString = ''\n","\n","#SampleCsv = 'https://adxsamplefiles.blob.core.windows.net/publiccsvsamples/logsbenchmark-onegb/2014/03/08/13/data.csv.gz' #222KB, 7530 rows\n","SampleCsv = 'https://adxsamplefiles.blob.core.windows.net/publiccsvsamples/logsbenchmark-onegb/2014/03/08/00/data.csv.gz' #7MB, 254424 rows"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"1e19c6c7-614f-434a-80ca-9635de97a643","statement_id":7,"state":"finished","livy_statement_state":"available","queued_time":"2023-10-20T13:52:21.148582Z","session_start_time":null,"execution_start_time":"2023-10-20T13:52:21.517977Z","execution_finish_time":"2023-10-20T13:52:21.9843124Z","spark_jobs":{"numbers":{"UNKNOWN":0,"RUNNING":0,"SUCCEEDED":0,"FAILED":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"6a6afa35-c4ac-46e8-8128-97e29253de19"},"text/plain":"StatementMeta(, 1e19c6c7-614f-434a-80ca-9635de97a643, 7, Finished, Available)"},"metadata":{}}],"execution_count":6,"metadata":{},"id":"11025a91-9ad5-4208-a18d-e78c945bd9c0"},{"cell_type":"markdown","source":["##### 2nd - installs required library"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"5c7a9f1f-faf8-4cbc-acbf-769e023d0d80"},{"cell_type":"code","source":["pip install azure-eventhub==5.11.5 --upgrade --force --quiet"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"1e19c6c7-614f-434a-80ca-9635de97a643","statement_id":8,"state":"finished","livy_statement_state":"available","queued_time":"2023-10-20T13:52:21.44155Z","session_start_time":null,"execution_start_time":"2023-10-20T13:52:22.3575787Z","execution_finish_time":"2023-10-20T13:52:24.263651Z","spark_jobs":{"numbers":{"UNKNOWN":0,"RUNNING":0,"SUCCEEDED":0,"FAILED":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"464ea6c4-81d2-4ef0-bb65-48766b5024b6"},"text/plain":"StatementMeta(, 1e19c6c7-614f-434a-80ca-9635de97a643, 8, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Note: you may need to restart the kernel to use updated packages.\n"]}],"execution_count":7,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"38577a4b-a2d9-48d7-876d-470f48d0b672"},{"cell_type":"markdown","source":["##### 3rd - imports required libraries"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"55789682-0486-4461-9b33-8196d22cf840"},{"cell_type":"code","source":["from pyspark import SparkFiles\n","from pyspark.sql.functions import col\n","import time\n","import os\n","import datetime\n","import json\n","from azure.eventhub import EventHubProducerClient, EventData"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"1e19c6c7-614f-434a-80ca-9635de97a643","statement_id":17,"state":"finished","livy_statement_state":"available","queued_time":"2023-10-20T14:05:33.8702484Z","session_start_time":null,"execution_start_time":"2023-10-20T14:05:34.2051218Z","execution_finish_time":"2023-10-20T14:05:34.6433982Z","spark_jobs":{"numbers":{"UNKNOWN":0,"RUNNING":0,"SUCCEEDED":0,"FAILED":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"7eaea9e2-09dc-4355-874c-32eade41dc74"},"text/plain":"StatementMeta(, 1e19c6c7-614f-434a-80ca-9635de97a643, 17, Finished, Available)"},"metadata":{}}],"execution_count":16,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"4a02865f-a03d-40ae-9732-9f87a9f969b5"},{"cell_type":"markdown","source":["##### 4th - sends the data"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"b8a6399d-5627-4f5f-bdfa-7fd014f38a29"},{"cell_type":"code","source":["spark.sparkContext.addFile(SampleCsv)\n","df = spark.read.options(header=\"false\").csv(\"file://\" + SparkFiles.get(\"data.csv.gz\"))\n","\n","df = df.select(\n","    col(\"_c0\").alias(\"Timestamp\"),\n","    col(\"_c1\").alias(\"Source\"),\n","    col(\"_c2\").alias(\"Node\"),\n","    col(\"_c3\").alias(\"Level\"),\n","    col(\"_c4\").alias(\"Component\"),\n","    col(\"_c5\").alias(\"ClientRequestId\"),\n","    col(\"_c6\").alias(\"Message\"),\n","    col(\"_c7\").alias(\"Properties\") \n",")#.take(1)\n","\n","# display(df.take(10))\n","# df.toJSON().collect()[0]"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"1e19c6c7-614f-434a-80ca-9635de97a643","statement_id":18,"state":"finished","livy_statement_state":"available","queued_time":"2023-10-20T14:05:49.5089515Z","session_start_time":null,"execution_start_time":"2023-10-20T14:05:49.8500786Z","execution_finish_time":"2023-10-20T14:05:51.8218183Z","spark_jobs":{"numbers":{"UNKNOWN":0,"RUNNING":0,"SUCCEEDED":1,"FAILED":0},"jobs":[{"displayName":"csv at NativeMethodAccessorImpl.java:0","dataWritten":0,"dataRead":65536,"rowCount":1,"usageDescription":"","jobId":12,"name":"csv at NativeMethodAccessorImpl.java:0","description":"Job group for statement 18:\nspark.sparkContext.addFile(SampleCsv)\ndf = spark.read.options(header=\"false\").csv(\"file://\" + SparkFiles.get(\"data.csv.gz\"))\n\ndf = df.select(\n    col(\"_c0\").alias(\"Timestamp\"),\n    col(\"_c1\").alias(\"Source\"),\n    col(\"_c2\").alias(\"Node\"),\n    col(\"_c3\").alias(\"Level\"),\n    col(\"_c4\").alias(\"Component\"),\n    col(\"_c5\").alias(\"ClientRequestId\"),\n    col(\"_c6\").alias(\"Message\"),\n    col(\"_c7\").alias(\"Properties\") \n)#.take(1)\n\n# display(df.take(10))\n# df.toJSON().collect()[0]","submissionTime":"2023-10-20T14:05:50.893GMT","completionTime":"2023-10-20T14:05:50.926GMT","stageIds":[16],"jobGroup":"18","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"d2a96b80-d61a-4bb9-af69-ac1835fe934c"},"text/plain":"StatementMeta(, 1e19c6c7-614f-434a-80ca-9635de97a643, 18, Finished, Available)"},"metadata":{}}],"execution_count":17,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"10dad469-2aa5-47e6-8c59-bdea6c1e4edc"},{"cell_type":"code","source":["producer = EventHubProducerClient.from_connection_string(conn_str=ConnectionString)\n","\n","z = df.count() \n","x = 0\n","y = 1\n","\n","for x in range(0, z): \n","    b = producer.create_batch() \n","    j = df.toJSON().collect()[x:y][0]\n","    # print(j)\n","    b.add(EventData(j))\n","    producer.send_batch(b) # send it!\n","    time.sleep(1)\n","    producer.close()\n","    x=y\n","    y=y+1"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"1e19c6c7-614f-434a-80ca-9635de97a643","statement_id":19,"state":"submitted","livy_statement_state":"running","queued_time":"2023-10-20T14:06:06.3340419Z","session_start_time":null,"execution_start_time":"2023-10-20T14:06:06.6825158Z","execution_finish_time":null,"spark_jobs":{"numbers":{"UNKNOWN":0,"RUNNING":1,"SUCCEEDED":85,"FAILED":0},"jobs":[{"displayName":"collect at /tmp/ipykernel_9465/1787748865.py:9","dataWritten":0,"dataRead":0,"rowCount":0,"usageDescription":"","jobId":98,"name":"collect at /tmp/ipykernel_9465/1787748865.py:9","description":"Job group for statement 19:\nproducer = EventHubProducerClient.from_connection_string(conn_str=ConnectionString)\n\nz = df.count() \nx = 0\ny = 1\n\nfor x in range(0, z): \n    b = producer.create_batch() \n    j = df.toJSON().collect()[x:y][0]\n    # print(j)\n    b.add(EventData(j))\n    producer.send_batch(b) # send it!\n    time.sleep(1)\n    producer.close()\n    x=y\n    y=y+1","submissionTime":"2023-10-20T14:12:26.000GMT","stageIds":[103],"jobGroup":"19","status":"RUNNING","numTasks":1,"numActiveTasks":0,"numCompletedTasks":0,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":0,"numActiveStages":1,"numCompletedStages":0,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9465/1787748865.py:9","dataWritten":0,"dataRead":7676425,"rowCount":254424,"usageDescription":"","jobId":97,"name":"collect at /tmp/ipykernel_9465/1787748865.py:9","description":"Job group for statement 19:\nproducer = EventHubProducerClient.from_connection_string(conn_str=ConnectionString)\n\nz = df.count() \nx = 0\ny = 1\n\nfor x in range(0, z): \n    b = producer.create_batch() \n    j = df.toJSON().collect()[x:y][0]\n    # print(j)\n    b.add(EventData(j))\n    producer.send_batch(b) # send it!\n    time.sleep(1)\n    producer.close()\n    x=y\n    y=y+1","submissionTime":"2023-10-20T14:12:21.501GMT","completionTime":"2023-10-20T14:12:23.700GMT","stageIds":[102],"jobGroup":"19","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9465/1787748865.py:9","dataWritten":0,"dataRead":7676425,"rowCount":254424,"usageDescription":"","jobId":96,"name":"collect at /tmp/ipykernel_9465/1787748865.py:9","description":"Job group for statement 19:\nproducer = EventHubProducerClient.from_connection_string(conn_str=ConnectionString)\n\nz = df.count() \nx = 0\ny = 1\n\nfor x in range(0, z): \n    b = producer.create_batch() \n    j = df.toJSON().collect()[x:y][0]\n    # print(j)\n    b.add(EventData(j))\n    producer.send_batch(b) # send it!\n    time.sleep(1)\n    producer.close()\n    x=y\n    y=y+1","submissionTime":"2023-10-20T14:12:17.035GMT","completionTime":"2023-10-20T14:12:19.268GMT","stageIds":[101],"jobGroup":"19","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9465/1787748865.py:9","dataWritten":0,"dataRead":7676425,"rowCount":254424,"usageDescription":"","jobId":95,"name":"collect at /tmp/ipykernel_9465/1787748865.py:9","description":"Job group for statement 19:\nproducer = EventHubProducerClient.from_connection_string(conn_str=ConnectionString)\n\nz = df.count() \nx = 0\ny = 1\n\nfor x in range(0, z): \n    b = producer.create_batch() \n    j = df.toJSON().collect()[x:y][0]\n    # print(j)\n    b.add(EventData(j))\n    producer.send_batch(b) # send it!\n    time.sleep(1)\n    producer.close()\n    x=y\n    y=y+1","submissionTime":"2023-10-20T14:12:12.453GMT","completionTime":"2023-10-20T14:12:14.692GMT","stageIds":[100],"jobGroup":"19","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9465/1787748865.py:9","dataWritten":0,"dataRead":7676425,"rowCount":254424,"usageDescription":"","jobId":94,"name":"collect at /tmp/ipykernel_9465/1787748865.py:9","description":"Job group for statement 19:\nproducer = EventHubProducerClient.from_connection_string(conn_str=ConnectionString)\n\nz = df.count() \nx = 0\ny = 1\n\nfor x in range(0, z): \n    b = producer.create_batch() \n    j = df.toJSON().collect()[x:y][0]\n    # print(j)\n    b.add(EventData(j))\n    producer.send_batch(b) # send it!\n    time.sleep(1)\n    producer.close()\n    x=y\n    y=y+1","submissionTime":"2023-10-20T14:12:07.998GMT","completionTime":"2023-10-20T14:12:10.225GMT","stageIds":[99],"jobGroup":"19","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9465/1787748865.py:9","dataWritten":0,"dataRead":7676425,"rowCount":254424,"usageDescription":"","jobId":93,"name":"collect at /tmp/ipykernel_9465/1787748865.py:9","description":"Job group for statement 19:\nproducer = EventHubProducerClient.from_connection_string(conn_str=ConnectionString)\n\nz = df.count() \nx = 0\ny = 1\n\nfor x in range(0, z): \n    b = producer.create_batch() \n    j = df.toJSON().collect()[x:y][0]\n    # print(j)\n    b.add(EventData(j))\n    producer.send_batch(b) # send it!\n    time.sleep(1)\n    producer.close()\n    x=y\n    y=y+1","submissionTime":"2023-10-20T14:12:03.497GMT","completionTime":"2023-10-20T14:12:05.721GMT","stageIds":[98],"jobGroup":"19","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9465/1787748865.py:9","dataWritten":0,"dataRead":7676425,"rowCount":254424,"usageDescription":"","jobId":92,"name":"collect at /tmp/ipykernel_9465/1787748865.py:9","description":"Job group for statement 19:\nproducer = EventHubProducerClient.from_connection_string(conn_str=ConnectionString)\n\nz = df.count() \nx = 0\ny = 1\n\nfor x in range(0, z): \n    b = producer.create_batch() \n    j = df.toJSON().collect()[x:y][0]\n    # print(j)\n    b.add(EventData(j))\n    producer.send_batch(b) # send it!\n    time.sleep(1)\n    producer.close()\n    x=y\n    y=y+1","submissionTime":"2023-10-20T14:11:59.017GMT","completionTime":"2023-10-20T14:12:01.282GMT","stageIds":[97],"jobGroup":"19","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9465/1787748865.py:9","dataWritten":0,"dataRead":7676425,"rowCount":254424,"usageDescription":"","jobId":91,"name":"collect at /tmp/ipykernel_9465/1787748865.py:9","description":"Job group for statement 19:\nproducer = EventHubProducerClient.from_connection_string(conn_str=ConnectionString)\n\nz = df.count() \nx = 0\ny = 1\n\nfor x in range(0, z): \n    b = producer.create_batch() \n    j = df.toJSON().collect()[x:y][0]\n    # print(j)\n    b.add(EventData(j))\n    producer.send_batch(b) # send it!\n    time.sleep(1)\n    producer.close()\n    x=y\n    y=y+1","submissionTime":"2023-10-20T14:11:54.366GMT","completionTime":"2023-10-20T14:11:56.716GMT","stageIds":[96],"jobGroup":"19","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9465/1787748865.py:9","dataWritten":0,"dataRead":7676425,"rowCount":254424,"usageDescription":"","jobId":90,"name":"collect at /tmp/ipykernel_9465/1787748865.py:9","description":"Job group for statement 19:\nproducer = EventHubProducerClient.from_connection_string(conn_str=ConnectionString)\n\nz = df.count() \nx = 0\ny = 1\n\nfor x in range(0, z): \n    b = producer.create_batch() \n    j = df.toJSON().collect()[x:y][0]\n    # print(j)\n    b.add(EventData(j))\n    producer.send_batch(b) # send it!\n    time.sleep(1)\n    producer.close()\n    x=y\n    y=y+1","submissionTime":"2023-10-20T14:11:49.831GMT","completionTime":"2023-10-20T14:11:52.145GMT","stageIds":[95],"jobGroup":"19","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9465/1787748865.py:9","dataWritten":0,"dataRead":7676425,"rowCount":254424,"usageDescription":"","jobId":89,"name":"collect at /tmp/ipykernel_9465/1787748865.py:9","description":"Job group for statement 19:\nproducer = EventHubProducerClient.from_connection_string(conn_str=ConnectionString)\n\nz = df.count() \nx = 0\ny = 1\n\nfor x in range(0, z): \n    b = producer.create_batch() \n    j = df.toJSON().collect()[x:y][0]\n    # print(j)\n    b.add(EventData(j))\n    producer.send_batch(b) # send it!\n    time.sleep(1)\n    producer.close()\n    x=y\n    y=y+1","submissionTime":"2023-10-20T14:11:45.348GMT","completionTime":"2023-10-20T14:11:47.541GMT","stageIds":[94],"jobGroup":"19","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9465/1787748865.py:9","dataWritten":0,"dataRead":7676425,"rowCount":254424,"usageDescription":"","jobId":88,"name":"collect at /tmp/ipykernel_9465/1787748865.py:9","description":"Job group for statement 19:\nproducer = EventHubProducerClient.from_connection_string(conn_str=ConnectionString)\n\nz = df.count() \nx = 0\ny = 1\n\nfor x in range(0, z): \n    b = producer.create_batch() \n    j = df.toJSON().collect()[x:y][0]\n    # print(j)\n    b.add(EventData(j))\n    producer.send_batch(b) # send it!\n    time.sleep(1)\n    producer.close()\n    x=y\n    y=y+1","submissionTime":"2023-10-20T14:11:40.873GMT","completionTime":"2023-10-20T14:11:43.083GMT","stageIds":[93],"jobGroup":"19","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9465/1787748865.py:9","dataWritten":0,"dataRead":7676425,"rowCount":254424,"usageDescription":"","jobId":87,"name":"collect at /tmp/ipykernel_9465/1787748865.py:9","description":"Job group for statement 19:\nproducer = EventHubProducerClient.from_connection_string(conn_str=ConnectionString)\n\nz = df.count() \nx = 0\ny = 1\n\nfor x in range(0, z): \n    b = producer.create_batch() \n    j = df.toJSON().collect()[x:y][0]\n    # print(j)\n    b.add(EventData(j))\n    producer.send_batch(b) # send it!\n    time.sleep(1)\n    producer.close()\n    x=y\n    y=y+1","submissionTime":"2023-10-20T14:11:36.385GMT","completionTime":"2023-10-20T14:11:38.591GMT","stageIds":[92],"jobGroup":"19","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9465/1787748865.py:9","dataWritten":0,"dataRead":7676425,"rowCount":254424,"usageDescription":"","jobId":86,"name":"collect at /tmp/ipykernel_9465/1787748865.py:9","description":"Job group for statement 19:\nproducer = EventHubProducerClient.from_connection_string(conn_str=ConnectionString)\n\nz = df.count() \nx = 0\ny = 1\n\nfor x in range(0, z): \n    b = producer.create_batch() \n    j = df.toJSON().collect()[x:y][0]\n    # print(j)\n    b.add(EventData(j))\n    producer.send_batch(b) # send it!\n    time.sleep(1)\n    producer.close()\n    x=y\n    y=y+1","submissionTime":"2023-10-20T14:11:31.912GMT","completionTime":"2023-10-20T14:11:34.159GMT","stageIds":[91],"jobGroup":"19","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9465/1787748865.py:9","dataWritten":0,"dataRead":7676425,"rowCount":254424,"usageDescription":"","jobId":85,"name":"collect at /tmp/ipykernel_9465/1787748865.py:9","description":"Job group for statement 19:\nproducer = EventHubProducerClient.from_connection_string(conn_str=ConnectionString)\n\nz = df.count() \nx = 0\ny = 1\n\nfor x in range(0, z): \n    b = producer.create_batch() \n    j = df.toJSON().collect()[x:y][0]\n    # print(j)\n    b.add(EventData(j))\n    producer.send_batch(b) # send it!\n    time.sleep(1)\n    producer.close()\n    x=y\n    y=y+1","submissionTime":"2023-10-20T14:11:27.342GMT","completionTime":"2023-10-20T14:11:29.623GMT","stageIds":[90],"jobGroup":"19","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9465/1787748865.py:9","dataWritten":0,"dataRead":7676425,"rowCount":254424,"usageDescription":"","jobId":84,"name":"collect at /tmp/ipykernel_9465/1787748865.py:9","description":"Job group for statement 19:\nproducer = EventHubProducerClient.from_connection_string(conn_str=ConnectionString)\n\nz = df.count() \nx = 0\ny = 1\n\nfor x in range(0, z): \n    b = producer.create_batch() \n    j = df.toJSON().collect()[x:y][0]\n    # print(j)\n    b.add(EventData(j))\n    producer.send_batch(b) # send it!\n    time.sleep(1)\n    producer.close()\n    x=y\n    y=y+1","submissionTime":"2023-10-20T14:11:22.831GMT","completionTime":"2023-10-20T14:11:25.055GMT","stageIds":[89],"jobGroup":"19","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9465/1787748865.py:9","dataWritten":0,"dataRead":7676425,"rowCount":254424,"usageDescription":"","jobId":83,"name":"collect at /tmp/ipykernel_9465/1787748865.py:9","description":"Job group for statement 19:\nproducer = EventHubProducerClient.from_connection_string(conn_str=ConnectionString)\n\nz = df.count() \nx = 0\ny = 1\n\nfor x in range(0, z): \n    b = producer.create_batch() \n    j = df.toJSON().collect()[x:y][0]\n    # print(j)\n    b.add(EventData(j))\n    producer.send_batch(b) # send it!\n    time.sleep(1)\n    producer.close()\n    x=y\n    y=y+1","submissionTime":"2023-10-20T14:11:18.308GMT","completionTime":"2023-10-20T14:11:20.529GMT","stageIds":[88],"jobGroup":"19","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9465/1787748865.py:9","dataWritten":0,"dataRead":7676425,"rowCount":254424,"usageDescription":"","jobId":82,"name":"collect at /tmp/ipykernel_9465/1787748865.py:9","description":"Job group for statement 19:\nproducer = EventHubProducerClient.from_connection_string(conn_str=ConnectionString)\n\nz = df.count() \nx = 0\ny = 1\n\nfor x in range(0, z): \n    b = producer.create_batch() \n    j = df.toJSON().collect()[x:y][0]\n    # print(j)\n    b.add(EventData(j))\n    producer.send_batch(b) # send it!\n    time.sleep(1)\n    producer.close()\n    x=y\n    y=y+1","submissionTime":"2023-10-20T14:11:13.858GMT","completionTime":"2023-10-20T14:11:16.057GMT","stageIds":[87],"jobGroup":"19","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9465/1787748865.py:9","dataWritten":0,"dataRead":7676425,"rowCount":254424,"usageDescription":"","jobId":81,"name":"collect at /tmp/ipykernel_9465/1787748865.py:9","description":"Job group for statement 19:\nproducer = EventHubProducerClient.from_connection_string(conn_str=ConnectionString)\n\nz = df.count() \nx = 0\ny = 1\n\nfor x in range(0, z): \n    b = producer.create_batch() \n    j = df.toJSON().collect()[x:y][0]\n    # print(j)\n    b.add(EventData(j))\n    producer.send_batch(b) # send it!\n    time.sleep(1)\n    producer.close()\n    x=y\n    y=y+1","submissionTime":"2023-10-20T14:11:09.349GMT","completionTime":"2023-10-20T14:11:11.559GMT","stageIds":[86],"jobGroup":"19","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9465/1787748865.py:9","dataWritten":0,"dataRead":7676425,"rowCount":254424,"usageDescription":"","jobId":80,"name":"collect at /tmp/ipykernel_9465/1787748865.py:9","description":"Job group for statement 19:\nproducer = EventHubProducerClient.from_connection_string(conn_str=ConnectionString)\n\nz = df.count() \nx = 0\ny = 1\n\nfor x in range(0, z): \n    b = producer.create_batch() \n    j = df.toJSON().collect()[x:y][0]\n    # print(j)\n    b.add(EventData(j))\n    producer.send_batch(b) # send it!\n    time.sleep(1)\n    producer.close()\n    x=y\n    y=y+1","submissionTime":"2023-10-20T14:11:04.789GMT","completionTime":"2023-10-20T14:11:07.070GMT","stageIds":[85],"jobGroup":"19","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"collect at /tmp/ipykernel_9465/1787748865.py:9","dataWritten":0,"dataRead":7676425,"rowCount":254424,"usageDescription":"","jobId":79,"name":"collect at /tmp/ipykernel_9465/1787748865.py:9","description":"Job group for statement 19:\nproducer = EventHubProducerClient.from_connection_string(conn_str=ConnectionString)\n\nz = df.count() \nx = 0\ny = 1\n\nfor x in range(0, z): \n    b = producer.create_batch() \n    j = df.toJSON().collect()[x:y][0]\n    # print(j)\n    b.add(EventData(j))\n    producer.send_batch(b) # send it!\n    time.sleep(1)\n    producer.close()\n    x=y\n    y=y+1","submissionTime":"2023-10-20T14:11:00.245GMT","completionTime":"2023-10-20T14:11:02.460GMT","stageIds":[84],"jobGroup":"19","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"f69500bf-d9dd-48b3-bc24-fb647a788080"},"text/plain":"StatementMeta(, 1e19c6c7-614f-434a-80ca-9635de97a643, 19, Submitted, Running)"},"metadata":{}}],"execution_count":18,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"6ce87a9c-2eab-48d1-861f-96962c718a89"}],"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"microsoft":{"host":{"synapse_widget":{"token":"7d5dba51-2687-4d36-b3e0-8806c6215f1f","state":{}}},"language":"python","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"kernel_info":{"name":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"enableDebugMode":false,"conf":{}}},"notebook_environment":{},"synapse_widget":{"version":"0.1","state":{}}},"nbformat":4,"nbformat_minor":5}
